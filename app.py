import io
import re
import altair as alt
import pandas as pd
import streamlit as st

# ========= Optional models (not required) =========
TRANSFORMERS_AVAILABLE = False
try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except Exception:
    TRANSFORMERS_AVAILABLE = False

st.set_page_config(page_title="ğŸ¤– ×“××• Streamlit â€” × ×ª×•× ×™× + AI", page_icon="ğŸ¤–", layout="wide")

# =======================
# Utilities
# =======================
def load_csv_bytes(file_obj) -> pd.DataFrame:
    if file_obj is None:
        return None
    data = file_obj.read()
    for enc in ("utf-8", "utf-8-sig", "windows-1255", "iso-8859-8"):
        try:
            return pd.read_csv(io.BytesIO(data), encoding=enc)
        except Exception:
            continue
    raise ValueError("×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”-CSV. ×‘×“×•×§/×™ ×§×™×“×•×“ ××• ××‘× ×” ×”×§×•×‘×¥.")

def ensure_numeric(series: pd.Series) -> pd.Series:
    s = pd.to_numeric(series, errors="coerce")
    return s.fillna(0.0).astype(float)

def guess_numeric_columns(df: pd.DataFrame) -> list:
    out = []
    for c in df.columns:
        try:
            pd.to_numeric(df[c], errors="coerce")
            out.append(c)
        except Exception:
            pass
    return out

def sanitize_field_name(name: str, default: str = "Value"):
    """
    ×× ×¨××œ ×©× ×©×“×” ×›×“×™ ×©×™×”×™×” ×‘×˜×•×— ×œ×©×™××•×© ×›×“×©× ×¢××•×“×” ×•×œ×˜×•×‘×ª Altair:
    - ×× ×¨×™×§ â†’ default
    - ××—×œ×™×£ ×ª×•×•×™× ×œ×-××•×ª/×¡×¤×¨×”/×§×•×• ×ª×—×ª×•×Ÿ ×œÖ¾'_'
    - ××§×¦×¨ ×¨×¦×¤×™× ×©×œ '_' ×•××¡×™×¨ ×§×¦×•×•×ª
    """
    if not name:
        return default, default
    raw = str(name).strip()
    if raw == "":
        return default, default
    safe = re.sub(r"[^\w]", "_", raw, flags=re.UNICODE)
    safe = re.sub(r"_+", "_", safe).strip("_")
    if safe == "":
        safe = default
    # safe ×”×•× ×©× ×”×¢××•×“×” ×‘×¤×•×¢×œ; raw ×™×•×¦×’ ×‘×›×•×ª×¨×ª ×”×¦×™×¨
    return safe, raw

def make_bar_chart(series: pd.Series, label: str = "Value"):
    """
    ×’×¨×£ ×¢××•×“×•×ª ×™×¦×™×‘ ×‘×××¦×¢×•×ª Altair:
    - ×”××¨×ª ×¢×¨×›×™× ×œ××¡×¤×¨×™×™× ×›×•×œ×œ 0
    - × ×¨××•×œ ×©× ×”×¡×“×¨×” ×›×“×™ ×œ×× ×•×¢ ×©×’×™××ª shorthand ×©×œ Altair
    - ×©×™××•×© ×‘-encode ××¤×•×¨×©: field=, type= (×œ× 'field:type')
    """
    ser = ensure_numeric(series)
    safe_label, raw_label = sanitize_field_name(label or "Value", default="Value")
    plot_df = pd.DataFrame({
        "Index": ser.index.astype(str),
        safe_label: ser.values
    })
    chart = (
        alt.Chart(plot_df)
        .mark_bar()
        .encode(
            x=alt.X(field="Index", type="nominal", title="Index"),
            y=alt.Y(field=safe_label, type="quantitative", title=raw_label),
        )
        .properties(height=320)
    )
    return chart

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    if df is None:
        return None
    df2 = df.copy()
    df2.columns = [str(c).strip() for c in df2.columns]
    for c in df2.columns:
        if pd.api.types.is_object_dtype(df2[c]):
            df2[c] = df2[c].apply(lambda x: str(x).strip() if pd.notna(x) else x)
    return df2

# ---------- AI helpers (no external services) ----------
_HE_STOPWORDS = {
    "×× ×™","××ª×”","××ª","×”×•×","×”×™×","×× ×—× ×•","××ª×","××ª×Ÿ","×”×","×”×Ÿ","×©×œ","×¢×","×¢×œ","××œ","×¢×“","××",
    "×™×©","××™×Ÿ","×××•×“","×’×","××‘×œ","××•","×›×™","×œ×","×›×Ÿ","×–×”","×–×•","×‘×™×Ÿ","×•×›×Ÿ","×›×š","×›×“×™","×”×™×•","×”×™×”",
}
_EN_STOPWORDS = {
    "i","you","he","she","it","we","they","the","a","an","of","to","in","on","and","or","but","is","are",
    "was","were","be","been","very","so","that","this","these","those","as","at","by","for","from","with","without"
}

def _tokenize_sentences(text: str):
    split = re.split(r'(?<=[\.\!\?\â€¦])\s+|\n+', text.strip())
    return [s.strip() for s in split if s.strip()]

def _word_tokens(text: str):
    return re.findall(r"[A-Za-z×-×ª]+", text.lower())

def _is_hebrew(text: str) -> bool:
    return bool(re.search(r"[×-×ª]", text))

def summarize_text_light(text: str, max_sentences: int = 5):
    if not text or not text.strip():
        return ""
    sentences = _tokenize_sentences(text)
    if len(sentences) <= max_sentences:
        return text.strip()
    heb = _is_hebrew(text)
    stop = _HE_STOPWORDS if heb else _EN_STOPWORDS
    words = _word_tokens(text)
    freq = {}
    for w in words:
        if w in stop:
            continue
        freq[w] = freq.get(w, 0) + 1
    scores = []
    for s in sentences:
        score = 0
        for w in _word_tokens(s):
            if w in stop:
                continue
            score += freq.get(w, 0)
        scores.append(score)
    ranked_idx = sorted(range(len(sentences)), key=lambda i: scores[i], reverse=True)[:max_sentences]
    ranked_idx = sorted(ranked_idx)
    summary = " ".join(sentences[i] for i in ranked_idx)
    return summary.strip()

def sentiment_simple(text: str):
    pos_he = {"××¢×•×œ×”","×˜×•×‘","××¦×•×™×Ÿ","×™×¤×”","××“×”×™×","×©××—×”","×—×™×•×‘×™","×—×–×§","××™×›×•×ª×™","×§×œ","××”×™×¨"}
    neg_he = {"×¨×¢","×’×¨×•×¢","×‘×¢×™×™×ª×™","×¢×¦×•×‘","×©×œ×™×œ×™","×§×©×”","××™×˜×™","×–×•×•×¢×”","××‘××¡","× ×•×¨×","×›×™×©×œ×•×Ÿ"}
    pos_en = {"good","great","excellent","nice","amazing","happy","positive","strong","quality","easy","fast"}
    neg_en = {"bad","terrible","problem","sad","negative","hard","slow","awful","worse","failure","annoying"}
    tokens = _word_tokens(text)
    if _is_hebrew(text):
        p = sum(t in pos_he for t in tokens)
        n = sum(t in neg_he for t in tokens)
    else:
        p = sum(t in pos_en for t in tokens)
        n = sum(t in neg_en for t in tokens)
    score = p - n
    label = "×—×™×•×‘×™" if score > 0 else ("×©×œ×™×œ×™" if score < 0 else "× ×™×˜×¨×œ×™")
    conf = min(1.0, max(0.0, 0.5 + abs(score) / 10))
    return {"label": label, "score": conf, "p": p, "n": n}

@st.cache_resource(show_spinner=False)
def get_sentiment_pipeline():
    if not TRANSFORMERS_AVAILABLE:
        return None
    try:
        return pipeline("sentiment-analysis")
    except Exception:
        return None

# =======================
# Sidebar
# =======================
st.sidebar.title("âš™ï¸ ×”×’×“×¨×•×ª")
user_name = st.sidebar.text_input("×©× ×œ×”×¦×™×’", value="×—×‘×¨/×”")
use_sample = st.sidebar.toggle("×”×©×ª××©/×™ ×‘× ×ª×•× ×™ ×“×•×’××”", value=False)
st.sidebar.caption("â¬‡ï¸ ×”×¢×œ××ª ×§×•×‘×¥ ××ª×‘×¦×¢×ª ×‘×œ×©×•× ×™×ª '× ×ª×•× ×™×'.")

# =======================
# Header
# =======================
st.title("ğŸ¤– ×“××• Streamlit â€” × ×ª×•× ×™× + AI ×§×œ×™×œ")
st.subheader(f"×©×œ×•× {user_name}! ğŸ‘‹")
st.write(
    "×”××¤×œ×™×§×¦×™×” ×›×•×œ×œ×ª: ×”×¢×œ××ª CSV, ×ª×¦×•×’×” ×•×¡×˜×˜×™×¡×˜×™×§×•×ª, ×’×¨×£ ×¢××•×“×•×ª ×™×¦×™×‘, ×•×œ×©×•× ×™×ª AI "
    "×¢× ×¡×™×›×•× ×˜×§×¡×˜ ×•× ×™×ª×•×— ×¡× ×˜×™×× ×˜ (×¢×/×‘×œ×™ transformers)."
)

# =======================
# Tabs
# =======================
tab_tasks, tab_data, tab_chart, tab_tools, tab_ai = st.tabs(
    ["âœ… ××©×™××•×ª", "ğŸ“„ × ×ª×•× ×™×", "ğŸ“Š ×’×¨×£", "ğŸ› ï¸ ×›×œ×™×", "ğŸ¤– AI"]
)

# =======================
# Tasks Tab
# =======================
with tab_tasks:
    st.markdown("### âœ… ×¨×©×™××ª ××©×™××•×ª (Session State)")
    if "todos" not in st.session_state:
        st.session_state.todos = []
    new_todo = st.text_input("×”×•×¡×£ ××©×™××” ×—×“×©×”", key="todo_input")
    add_col, _ = st.columns([0.2, 0.8])
    if add_col.button("â• ×”×•×¡×£"):
        if new_todo and new_todo.strip():
            st.session_state.todos.append({"text": new_todo.strip(), "done": False})
            st.success("× ×•×¡×£!")
        else:
            st.warning("×¨×©×•×/×™ ×˜×§×¡×˜ ×œ××©×™××”.")
    st.divider()
    to_remove = []
    for i, todo in enumerate(st.session_state.todos):
        c1, c2, c3 = st.columns([0.08, 0.77, 0.15])
        with c1:
            st.session_state.todos[i]["done"] = st.checkbox("×‘×•×¦×¢", value=todo["done"], key=f"todo_done_{i}")
        with c2:
            st.write(("~~" + todo["text"] + "~~") if st.session_state.todos[i]["done"] else todo["text"])
        with c3:
            if st.button("ğŸ—‘ï¸ ××—×™×§×”", key=f"todo_del_{i}"):
                to_remove.append(i)
    for idx in reversed(to_remove):
        st.session_state.todos.pop(idx)

# =======================
# Data Tab  (×›××Ÿ × ××¦× ×›×¤×ª×•×¨ ×”×”×¢×œ××”!)
# =======================
with tab_data:
    st.markdown("### ğŸ“„ ×˜×¢×™× ×ª × ×ª×•× ×™× (×›××Ÿ ××¢×œ×™× ×§×•×‘×¥)")
    st.caption("×‘×—×¨/×™ ×§×•×‘×¥ CSV ×œ×”×¢×œ××”, ××• ×”×©×ª××©/×™ ×‘× ×ª×•× ×™ ×”×“×•×’××” (××ª×’ ×‘Ö¾Sidebar).")
    df = None
    if use_sample:
        df = pd.DataFrame({"Category": ["A","B","C","D"], "Value": [10,0,7,15], "Note": ["××œ×¤×","×‘×˜×","×’×××","×“×œ×ª×"]})
    uploaded = st.file_uploader("×‘×—×¨/×™ ×§×•×‘×¥ CSV ×œ×”×¢×œ××”", type=["csv"], accept_multiple_files=False)
    if (df is None) and (uploaded is not None):
        try:
            df = load_csv_bytes(uploaded)
        except Exception as e:
            st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”×§×•×‘×¥: {e}")
    if df is not None:
        df = clean_dataframe(df)
        st.session_state.df = df.copy()
        st.success(f"× ×˜×¢× ×• {df.shape[0]} ×©×•×¨×•×ª ×•-{df.shape[1]} ×¢××•×“×•×ª.")
        st.write("**×ª×¦×•×’×”:**")
        st.dataframe(df, use_container_width=True)
        st.markdown("#### ğŸ§® ×¡×˜×˜×™×¡×˜×™×§×•×ª ××”×™×¨×•×ª")
        st.dataframe(df.describe(include="all").transpose(), use_container_width=True)
        st.markdown("#### ğŸ’¾ ×”×•×¨×“×ª ×”× ×ª×•× ×™× (CSV)")
        st.download_button("×”×•×¨×“ CSV ××¢×•×“×›×Ÿ", data=df.to_csv(index=False).encode("utf-8"),
                           file_name="data_clean.csv", mime="text/csv")
    else:
        st.info("×˜×¨× × ×˜×¢× ×• × ×ª×•× ×™×. ×”×¢×œ×”/×™ CSV ×›××Ÿ ×œ××¢×œ×” ××• ×”×¤×¢×œ/×™ × ×ª×•× ×™ ×“×•×’××” ××”Ö¾Sidebar.")

# =======================
# Chart Tab
# =======================
with tab_chart:
    st.markdown("### ğŸ“Š ×’×¨×£ ×¢××•×“×•×ª ×™×¦×™×‘ (×›×•×œ×œ ×ª××™×›×” ×‘×¢×¨×›×™ 0)")
    if "df" not in st.session_state:
        st.info("×¨××©×™×ª, ×˜×¢×Ÿ/×™ × ×ª×•× ×™× ×‘×œ×©×•× ×™×ª '× ×ª×•× ×™×'.")
    else:
        df = st.session_state.df.copy()
        numeric_cols = guess_numeric_columns(df)
        if not numeric_cols:
            st.warning("×œ× × ××¦××• ×¢××•×“×•×ª ×©× ×™×ª×Ÿ ×œ×”××™×¨ ×œ××¡×¤×¨×™×•×ª.")
        else:
            col = st.selectbox("×‘×—×¨/×™ ×¢××•×“×” ××¡×¤×¨×™×ª", options=numeric_cols, index=0)
            # ×ª×•×•×™×ª ×¦×™×¨-Y â€” ×¢×œ×•×œ×” ×œ×”×™×•×ª ×¨×™×§×”; × ×¡× ×Ÿ ××•×ª×” ×œ×¤× ×™× ×‘×˜×•×—×•×ª:
            user_label = st.text_input("×ª×•×•×™×ª ×¦×™×¨-Y (×©× ×”×¡×“×¨×”)", value=col or "Value")
            safe_label, raw_label = sanitize_field_name(user_label or "Value", default="Value")

            cat_opts = ["(Index)"] + df.columns.tolist()
            cat_col = st.selectbox("×‘×—×¨/×™ ×¢××•×“×ª ×§×˜×’×•×¨×™×” (×œ× ×—×•×‘×”)", options=cat_opts, index=0)

            series = ensure_numeric(df[col])

            if cat_col == "(Index)":
                # ××©×ª××©×™× ×‘×’×¨×£ ×”×¡×˜× ×“×¨×˜×™ ×©×× ×¨××œ ×©× ×”×¡×“×¨×” ×¤× ×™××™×ª
                chart = make_bar_chart(series, label=user_label or "Value")
            else:
                grouped = (
                    pd.DataFrame({"cat": df[cat_col].astype(str), safe_label: series})
                    .groupby("cat", as_index=False)[safe_label].sum()
                )
                chart = (
                    alt.Chart(grouped)
                    .mark_bar()
                    .encode(
                        x=alt.X(field="cat", type="nominal", title=cat_col),
                        y=alt.Y(field=safe_label, type="quantitative", title=raw_label),
                    )
                    .properties(height=340)
                )
            st.altair_chart(chart, use_container_width=True)

# =======================
# Tools Tab
# =======================
with tab_tools:
    st.markdown("### ğŸ› ï¸ ×›×œ×™×")
    if "df" in st.session_state:
        df = st.session_state.df.copy()
        st.markdown("#### ×˜×™×¤×•×¡×™× ×•-Nulls")
        info_df = pd.DataFrame({"dtype": df.dtypes.astype(str), "nulls": df.isna().sum()})
        st.dataframe(info_df, use_container_width=True)
        st.markdown("#### ×”××¨×ª ×¢××•×“×•×ª ×œ××¡×¤×¨×™×™× (coerceâ†’NaNâ†’0)")
        cols_to_convert = st.multiselect(
            "×‘×—×¨/×™ ×¢××•×“×•×ª ×œ×”××¨×”",
            options=df.columns.tolist(),
            default=[c for c in df.columns if c.lower() in ("value", "amount", "price")],
        )
        if st.button("×”××¨/×™ ×œ××¡×¤×¨×™×™×"):
            for c in cols_to_convert:
                df[c] = ensure_numeric(df[c])
            st.session_state.df = df
            st.success("×”×¢××•×“×•×ª ×”×•××¨×•. ×¢×‘×¨/×™ ×œ×œ×©×•× ×™×ª '×’×¨×£' ×›×“×™ ×œ×”××—×™×©.")
            st.dataframe(df.head(30), use_container_width=True)
    else:
        st.info("×¨××©×™×ª, ×˜×¢×Ÿ/×™ × ×ª×•× ×™× ×‘×œ×©×•× ×™×ª '× ×ª×•× ×™×'.")

# =======================
# AI Tab
# =======================
def get_stopwords_sets():
    HE = _HE_STOPWORDS
    EN = _EN_STOPWORDS
    return HE, EN

_HE_STOPWORDS = {
    "×× ×™","××ª×”","××ª","×”×•×","×”×™×","×× ×—× ×•","××ª×","××ª×Ÿ","×”×","×”×Ÿ","×©×œ","×¢×","×¢×œ","××œ","×¢×“","××",
    "×™×©","××™×Ÿ","×××•×“","×’×","××‘×œ","××•","×›×™","×œ×","×›×Ÿ","×–×”","×–×•","×‘×™×Ÿ","×•×›×Ÿ","×›×š","×›×“×™","×”×™×•","×”×™×”",
}
_EN_STOPWORDS = {
    "i","you","he","she","it","we","they","the","a","an","of","to","in","on","and","or","but","is","are",
    "was","were","be","been","very","so","that","this","these","those","as","at","by","for","from","with","without"
}

with tab_ai:
    st.markdown("## ğŸ¤– ×›×œ×™× ×—×›××™× (×œ×œ× ××™× ×˜×’×¨×¦×™×” ×—×™×¦×•× ×™×ª)")
    st.caption("×¡×™×›×•× ×˜×§×¡×˜ ×•× ×™×ª×•×— ×¡× ×˜×™×× ×˜. ×× ××•×ª×§×Ÿ transformers â€” ×™×•×¤×¢×œ ××•×“×œ ×¡× ×˜×™×× ×˜ '×××™×ª×™'; ××—×¨×ª, × ×™×ª×•×— ×§×œ×™×œ ××•×‘× ×”.")

    st.markdown("### âœ‚ï¸ ×¡×™×›×•× ×˜×§×¡×˜")
    text_to_sum = st.text_area("×”×“×‘×§/×™ ××• ×›×ª×•×‘/×™ ×˜×§×¡×˜ ×œ×¡×™×›×•×", height=160, placeholder="×”×›× ×¡/×™ ×˜×§×¡×˜ ×‘×¢×‘×¨×™×ª ××• ×‘×× ×’×œ×™×ª...")
    max_sents = st.slider("××¡×¤×¨ ××©×¤×˜×™× ×‘×¡×™×›×•×", min_value=2, max_value=10, value=5, step=1)
    if st.button("×¡×›×/×™"):
        if text_to_sum.strip():
            summary = summarize_text_light(text_to_sum, max_sentences=max_sents)
            st.write("**×¡×™×›×•×:**")
            st.write(summary)
        else:
            st.warning("× × ×œ×”×–×™×Ÿ ×˜×§×¡×˜.")

    st.divider()
    st.markdown("### ğŸ™‚ × ×™×ª×•×— ×¡× ×˜×™×× ×˜")
    sent_text = st.text_area("×˜×§×¡×˜ ×œ× ×™×ª×•×— ×¨×’×©", height=120, placeholder="×›×ª×•×‘/×™ ××©×¤×˜ ×œ×”×¢×¨×›×ª ×—×™×•×‘×™/×©×œ×™×œ×™/× ×™×˜×¨×œ×™")
    use_transformers = st.toggle("×”×©×ª××©/×™ ×‘-transformers ×× ×–××™×Ÿ", value=TRANSFORMERS_AVAILABLE)
    if st.button("× ×ª×—/×™"):
        if not sent_text.strip():
            st.warning("× × ×œ×”×–×™×Ÿ ×˜×§×¡×˜.")
        else:
            if use_transformers and TRANSFORMERS_AVAILABLE:
                nlp = get_sentiment_pipeline()
                if nlp is None:
                    st.info("×œ× × ××¦× ××•×“×œ ×–××™×Ÿ, ××©×ª××©×™× ×‘× ×™×ª×•×— ×”×§×œ×™×œ.")
                    res = sentiment_simple(sent_text)
                    st.write(f"**×ª×•×¦××”:** {res['label']} (×‘×˜×—×•×Ÿ {res['score']:.2f})")
                else:
                    out = nlp(sent_text)[0]
                    label = out.get("label", "")
                    score = out.get("score", 0.0)
                    st.write(f"**×ª×•×¦××” (transformers):** {label} (×‘×˜×—×•×Ÿ {score:.2f})")
            else:
                res = sentiment_simple(sent_text)
                st.write(f"**×ª×•×¦××”:** {res['label']} (×‘×˜×—×•×Ÿ {res['score']:.2f})")
                st.caption("×˜×™×¤: ×œ×”×ª× ×¡×•×ª ×‘××•×“×œ ×××™×ª×™, ×”×•×¡×£/×™ ×œ×—×‘×™×œ×•×ª: transformers, torch (××•×¤×¦×™×•× ×œ×™).")

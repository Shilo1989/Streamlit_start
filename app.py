import io
import re
import os
import altair as alt
import pandas as pd
import streamlit as st
import sqlite3
import tempfile

# ========= Optional models (not required) =========
TRANSFORMERS_AVAILABLE = False
try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except Exception:
    TRANSFORMERS_AVAILABLE = False

st.set_page_config(page_title="ğŸ¤– ×“××• Streamlit â€” × ×ª×•× ×™× + AI", page_icon="ğŸ¤–", layout="wide")

# =======================
# Utilities
# =======================
def load_csv_bytes(file_obj) -> pd.DataFrame:
    """×§×¨×™××ª CSV ××ª×•×š UploadedFile (×›××” ×§×™×“×•×“×™× × ×¤×•×¦×™×, ×›×•×œ×œ ×¢×‘×¨×™×ª)."""
    if file_obj is None:
        return None
    data = file_obj.read()
    for enc in ("utf-8", "utf-8-sig", "windows-1255", "iso-8859-8"):
        try:
            return pd.read_csv(io.BytesIO(data), encoding=enc)
        except Exception:
            continue
    raise ValueError("×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”-CSV. ×‘×“×•×§/×™ ×§×™×“×•×“ ××• ××‘× ×” ×”×§×•×‘×¥.")

def load_excel_bytes(file_obj) -> dict:
    """
    ×§×¨×™××ª Excel ××ª×•×š UploadedFile ×•×”×—×–×¨×” ×©×œ ××™×œ×•×Ÿ {sheet_name: DataFrame}.
    ××¦×¨×™×š openpyxl ×œ-xlsx.
    """
    if file_obj is None:
        return None
    data = file_obj.read()
    xls = pd.ExcelFile(io.BytesIO(data))
    sheets = {}
    for sheet in xls.sheet_names:
        try:
            sheets[sheet] = pd.read_excel(xls, sheet_name=sheet)
        except Exception:
            pass
    if not sheets:
        raise ValueError("×œ× × ××¦××• ×’×™×œ×™×•× ×•×ª ×§×¨×™××™× ×‘×§×•×‘×¥ ×”××§×¡×œ.")
    return sheets

# --------- SQLite helpers: ×œ× ×˜×•×¢× ×™× ×”×›×œ ××¨××© ---------
def _sqlite_bytes_to_tempfile(db_bytes: bytes) -> str:
    """×©×•××¨ ×‘×™×™×˜×™× ×©×œ DB ×œ×§×•×‘×¥ ×–×× ×™ ×•××—×–×™×¨ ××ª ×”× ×ª×™×‘."""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".db") as tmp:
        tmp.write(db_bytes)
        return tmp.name

def get_sqlite_table_names(db_bytes: bytes) -> list:
    """××—×–×™×¨ ×¨×©×™××ª ×˜×‘×œ××•×ª ××ª×•×š ×”-DB ×‘×œ×™ ×œ×˜×¢×•×Ÿ ××•×ª×Ÿ."""
    path = _sqlite_bytes_to_tempfile(db_bytes)
    try:
        con = sqlite3.connect(path)
        cur = con.cursor()
        cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name;")
        rows = cur.fetchall()
        return [r[0] for r in rows]
    finally:
        try:
            con.close()
        except Exception:
            pass
        try:
            os.remove(path)
        except Exception:
            pass

def read_sqlite_table(db_bytes: bytes, table: str, limit: int = 100000) -> pd.DataFrame:
    """×§×•×¨× ×˜×‘×œ×” ×‘×•×“×“×ª ×œ×¤×™ ×©×, ×¢× LIMIT ×‘×˜×™×—×•×ª×™ (×‘×¨×™×¨×ª ××—×“×œ 100k)."""
    path = _sqlite_bytes_to_tempfile(db_bytes)
    try:
        con = sqlite3.connect(path)
        q = f"SELECT * FROM '{table}'"
        if limit and limit > 0:
            q += f" LIMIT {int(limit)}"
        df = pd.read_sql_query(q, con)
        return df
    finally:
        try:
            con.close()
        except Exception:
            pass
        try:
            os.remove(path)
        except Exception:
            pass

def ensure_numeric(series: pd.Series) -> pd.Series:
    s = pd.to_numeric(series, errors="coerce")
    return s.fillna(0.0).astype(float)

def guess_numeric_columns(df: pd.DataFrame) -> list:
    out = []
    for c in df.columns:
        try:
            pd.to_numeric(df[c], errors="coerce")
            out.append(c)
        except Exception:
            pass
    return out

def sanitize_field_name(name: str, default: str = "Value"):
    if not name:
        return default, default
    raw = str(name).strip()
    if raw == "":
        return default, default
    safe = re.sub(r"[^\w]", "_", raw, flags=re.UNICODE)
    safe = re.sub(r"_+", "_", safe).strip("_")
    if safe == "":
        safe = default
    return safe, raw

def make_bar_chart(series: pd.Series, label: str = "Value"):
    ser = ensure_numeric(series)
    safe_label, raw_label = sanitize_field_name(label or "Value", default="Value")
    plot_df = pd.DataFrame({"Index": ser.index.astype(str), safe_label: ser.values})
    chart = (
        alt.Chart(plot_df)
        .mark_bar()
        .encode(
            x=alt.X(field="Index", type="nominal", title="Index"),
            y=alt.Y(field=safe_label, type="quantitative", title=raw_label),
        )
        .properties(height=320)
    )
    return chart

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    if df is None:
        return None
    df2 = df.copy()
    df2.columns = [str(c).strip() for c in df2.columns]
    for c in df2.columns:
        if pd.api.types.is_object_dtype(df2[c]):
            df2[c] = df2[c].apply(lambda x: str(x).strip() if pd.notna(x) else x)
    return df2

# ---------- AI helpers (no external services) ----------
_HE_STOPWORDS = {
    "×× ×™","××ª×”","××ª","×”×•×","×”×™×","×× ×—× ×•","××ª×","××ª×Ÿ","×”×","×”×Ÿ","×©×œ","×¢×","×¢×œ","××œ","×¢×“","××",
    "×™×©","××™×Ÿ","×××•×“","×’×","××‘×œ","××•","×›×™","×œ×","×›×Ÿ","×–×”","×–×•","×‘×™×Ÿ","×•×›×Ÿ","×›×š","×›×“×™","×”×™×•","×”×™×”",
}
_EN_STOPWORDS = {
    "i","you","he","she","it","we","they","the","a","an","of","to","in","on","and","or","but","is","are",
    "was","were","be","been","very","so","that","this","these","those","as","at","by","for","from","with","without"
}

def _tokenize_sentences(text: str):
    split = re.split(r'(?<=[\.\!\?\â€¦])\s+|\n+', text.strip())
    return [s.strip() for s in split if s.strip()]

def _word_tokens(text: str):
    return re.findall(r"[A-Za-z×-×ª]+", text.lower())

def _is_hebrew(text: str) -> bool:
    return bool(re.search(r"[×-×ª]", text))

def summarize_text_light(text: str, max_sentences: int = 5):
    if not text or not text.strip():
        return ""
    sentences = _tokenize_sentences(text)
    if len(sentences) <= max_sentences:
        return text.strip()
    heb = _is_hebrew(text)
    stop = _HE_STOPWORDS if heb else _EN_STOPWORDS
    words = _word_tokens(text)
    freq = {}
    for w in words:
        if w in stop:
            continue
        freq[w] = freq.get(w, 0) + 1
    scores = []
    for s in sentences:
        score = 0
        for w in _word_tokens(s):
            if w in stop:
                continue
            score += freq.get(w, 0)
        scores.append(score)
    ranked_idx = sorted(range(len(sentences)), key=lambda i: scores[i], reverse=True)[:max_sentences]
    ranked_idx = sorted(ranked_idx)
    summary = " ".join(sentences[i] for i in ranked_idx)
    return summary.strip()

def sentiment_simple(text: str):
    pos_he = {"××¢×•×œ×”","×˜×•×‘","××¦×•×™×Ÿ","×™×¤×”","××“×”×™×","×©××—×”","×—×™×•×‘×™","×—×–×§","××™×›×•×ª×™","×§×œ","××”×™×¨"}
    neg_he = {"×¨×¢","×’×¨×•×¢","×‘×¢×™×™×ª×™","×¢×¦×•×‘","×©×œ×™×œ×™","×§×©×”","××™×˜×™","×–×•×•×¢×”","××‘××¡","× ×•×¨×","×›×™×©×œ×•×Ÿ"}
    pos_en = {"good","great","excellent","nice","amazing","happy","positive","strong","quality","easy","fast"}
    neg_en = {"bad","terrible","problem","sad","negative","hard","slow","awful","worse","failure","annoying"}
    tokens = _word_tokens(text)
    if _is_hebrew(text):
        p = sum(t in pos_he for t in tokens)
        n = sum(t in neg_he for t in tokens)
    else:
        p = sum(t in pos_en for t in tokens)
        n = sum(t in neg_en for t in tokens)
    score = p - n
    label = "×—×™×•×‘×™" if score > 0 else ("×©×œ×™×œ×™" if score < 0 else "× ×™×˜×¨×œ×™")
    conf = min(1.0, max(0.0, 0.5 + abs(score) / 10))
    return {"label": label, "score": conf, "p": p, "n": n}

@st.cache_resource(show_spinner=False)
def get_sentiment_pipeline():
    if not TRANSFORMERS_AVAILABLE:
        return None
    try:
        return pipeline("sentiment-analysis")
    except Exception:
        return None

# =======================
# Sidebar
# =======================
st.sidebar.title("âš™ï¸ ×”×’×“×¨×•×ª")
user_name = st.sidebar.text_input("×©× ×œ×”×¦×™×’", value="×—×‘×¨/×”")
use_sample = st.sidebar.toggle("×”×©×ª××©/×™ ×‘× ×ª×•× ×™ ×“×•×’××”", value=False)
st.sidebar.caption("â¬‡ï¸ ×”×¢×œ××ª ×§×•×‘×¥ ××ª×‘×¦×¢×ª ×‘×œ×©×•× ×™×ª '× ×ª×•× ×™×'.")

# =======================
# Header
# =======================
st.title("ğŸ¤– ×“××• Streamlit â€” × ×ª×•× ×™× + AI ×§×œ×™×œ")
st.subheader(f"×©×œ×•× {user_name}! ğŸ‘‹")
st.write(
    "×”××¤×œ×™×§×¦×™×” ×ª×•××›×ª ×‘: CSV, Excel (.xlsx/.xls), ×•-SQLite DB (.db/.sqlite). "
    "×‘-DB: ××•×¦×’×ª ×¨×©×™××ª ×˜×‘×œ××•×ª ×œ×‘×—×™×¨×”, ×•××– × ×˜×¢× ×ª ×¨×§ ×”×˜×‘×œ×” ×©× ×‘×—×¨×”. ×™×© ×’× ×œ×©×•× ×™×ª AI."
)

# =======================
# Tabs
# =======================
tab_tasks, tab_data, tab_chart, tab_tools, tab_ai = st.tabs(
    ["âœ… ××©×™××•×ª", "ğŸ“„ × ×ª×•× ×™×", "ğŸ“Š ×’×¨×£", "ğŸ› ï¸ ×›×œ×™×", "ğŸ¤– AI"]
)

# =======================
# Tasks Tab
# =======================
with tab_tasks:
    st.markdown("### âœ… ×¨×©×™××ª ××©×™××•×ª (Session State)")
    if "todos" not in st.session_state:
        st.session_state.todos = []
    new_todo = st.text_input("×”×•×¡×£ ××©×™××” ×—×“×©×”", key="todo_input")
    add_col, _ = st.columns([0.2, 0.8])
    if add_col.button("â• ×”×•×¡×£"):
        if new_todo and new_todo.strip():
            st.session_state.todos.append({"text": new_todo.strip(), "done": False})
            st.success("× ×•×¡×£!")
        else:
            st.warning("×¨×©×•×/×™ ×˜×§×¡×˜ ×œ××©×™××”.")
    st.divider()
    to_remove = []
    for i, todo in enumerate(st.session_state.todos):
        c1, c2, c3 = st.columns([0.08, 0.77, 0.15])
        with c1:
            st.session_state.todos[i]["done"] = st.checkbox("×‘×•×¦×¢", value=todo["done"], key=f"todo_done_{i}")
        with c2:
            st.write(("~~" + todo["text"] + "~~") if st.session_state.todos[i]["done"] else todo["text"])
        with c3:
            if st.button("ğŸ—‘ï¸ ××—×™×§×”", key=f"todo_del_{i}"):
                to_remove.append(i)
    for idx in reversed(to_remove):
        st.session_state.todos.pop(idx)

# =======================
# Data Tab
# =======================
with tab_data:
    st.markdown("### ğŸ“„ ×˜×¢×™× ×ª × ×ª×•× ×™× (CSV / Excel / SQLite-DB)")
    st.caption("×‘×—×¨/×™ ×§×•×‘×¥ ×œ×”×¢×œ××”, ××• ×”×©×ª××©/×™ ×‘× ×ª×•× ×™ ×”×“×•×’××” (××ª×’ ×‘-Sidebar).")

    df = None

    # × ×ª×•× ×™ ×“×•×’××” (××•×¤×¦×™×•× ×œ×™)
    if use_sample:
        df = pd.DataFrame(
            {"Category": ["A","B","C","D"], "Value": [10,0,7,15], "Note": ["××œ×¤×","×‘×˜×","×’×××","×“×œ×ª×"]}
        )

    uploaded = st.file_uploader(
        "×‘×—×¨/×™ ×§×•×‘×¥: CSV / XLSX / XLS / DB / SQLITE",
        type=["csv", "xlsx", "xls", "db", "sqlite"],
        accept_multiple_files=False
    )

    excel_sheets = None
    chosen_name = None

    # --- SQLite state ---
    if "db_bytes" not in st.session_state:
        st.session_state.db_bytes = None
    if "db_tables" not in st.session_state:
        st.session_state.db_tables = []
    if "db_selected_table" not in st.session_state:
        st.session_state.db_selected_table = None

    if (df is None) and (uploaded is not None):
        name_lower = (uploaded.name or "").lower()
        try:
            if name_lower.endswith(".csv"):
                df = load_csv_bytes(uploaded)
                chosen_name = uploaded.name

            elif name_lower.endswith(".xlsx") or name_lower.endswith(".xls"):
                # ×˜×•×¢× ×™× ×’×™×œ×™×•× ×•×ª ×•×××¤×©×¨×™× ×œ×‘×—×•×¨
                excel_sheets = load_excel_bytes(uploaded)
                if excel_sheets:
                    sheet = st.selectbox("×‘×—×¨/×™ ×’×™×œ×™×•×Ÿ ×œ×”×¦×’×”", options=list(excel_sheets.keys()))
                    df = excel_sheets.get(sheet)
                    chosen_name = f"{uploaded.name} â€” {sheet}"

            elif name_lower.endswith(".db") or name_lower.endswith(".sqlite"):
                # ×©×•××¨×™× ××ª ×”-DB ×‘×‘×™×™×˜×™× ×œ-Session State ×¤×¢× ××—×ª
                db_raw = uploaded.read()
                st.session_state.db_bytes = db_raw
                # ××§×‘×œ×™× ×©××•×ª ×˜×‘×œ××•×ª ×•××¦×™×’×™× ×œ×‘×—×™×¨×”
                st.session_state.db_tables = get_sqlite_table_names(st.session_state.db_bytes)
                if not st.session_state.db_tables:
                    st.error("×œ× × ××¦××• ×˜×‘×œ××•×ª ×‘-DB.")
                else:
                    st.markdown("#### ×˜×‘×œ××•×ª ×©× ××¦××• ×‘-DB")
                    st.write(st.session_state.db_tables)
                    st.session_state.db_selected_table = st.selectbox(
                        "×‘×—×¨/×™ ×˜×‘×œ×” ×œ×”×¦×’×”",
                        options=st.session_state.db_tables,
                        index=0
                    )
                    limit = st.number_input("LIMIT ×œ×ª×¦×•×’×” (×œ×©××™×¨×” ×¢×œ ×–×™×›×¨×•×Ÿ)", min_value=1000, max_value=1_000_000, step=1000, value=100000)
                    if st.button("×˜×¢×Ÿ ×˜×‘×œ×”"):
                        try:
                            df = read_sqlite_table(st.session_state.db_bytes, st.session_state.db_selected_table, int(limit))
                            chosen_name = f"{uploaded.name} â€” {st.session_state.db_selected_table}"
                        except Exception as e:
                            st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”×˜×‘×œ×”: {e}")

                    # ××•×¤×¦×™×•× ×œ×™: ×©××™×œ×ª×ª SQL ×—×•×¤×©×™×ª ×‘×˜×•×—×” ×¢× LIMIT
                    with st.expander("ğŸ§ª ×©××™×œ×ª×ª SQL (××•×¤×¦×™×•× ×œ×™)"):
                        st.caption("××¤×©×¨ ×œ×›×ª×•×‘ SELECT ×¢×œ ×”-DB (× ×•×¡×™×£ LIMIT ×× ×—×¡×¨).")
                        sql = st.text_area("×©××™×œ×ª× (×œ××©×œ: SELECT * FROM my_table WHERE ...)", height=120)
                        if st.button("×”×¨×¥ ×©××™×œ×ª×"):
                            if sql.strip():
                                q = sql.strip().rstrip(";")
                                if "limit" not in q.lower():
                                    q += " LIMIT 100000"
                                try:
                                    # ×§×•×‘×¥ ×–×× ×™ ××”×¨×©×™××” ×‘-Session
                                    tmp_path = _sqlite_bytes_to_tempfile(st.session_state.db_bytes)
                                    try:
                                        con = sqlite3.connect(tmp_path)
                                        df_query = pd.read_sql_query(q, con)
                                        df = df_query
                                        chosen_name = f"SQL query"
                                        st.success("×”×©××™×œ×ª× ×¨×¦×” ×‘×”×¦×œ×—×”.")
                                    finally:
                                        try:
                                            con.close()
                                        except Exception:
                                            pass
                                        try:
                                            os.remove(tmp_path)
                                        except Exception:
                                            pass
                                except Exception as e:
                                    st.error(f"×©×’×™××” ×‘×”×¨×¦×ª ×”×©××™×œ×ª×: {e}")

            else:
                st.error("×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š.")

        except Exception as e:
            st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”×§×•×‘×¥: {e}")

    if df is not None:
        df = clean_dataframe(df)
        st.session_state.df = df.copy()
        st.success(f"× ×˜×¢× ×• {df.shape[0]} ×©×•×¨×•×ª ×•-{df.shape[1]} ×¢××•×“×•×ª." + (f" ({chosen_name})" if chosen_name else ""))
        st.write("**×ª×¦×•×’×”:**")
        st.dataframe(df, use_container_width=True)

        st.markdown("#### ğŸ§® ×¡×˜×˜×™×¡×˜×™×§×•×ª ××”×™×¨×•×ª")
        st.dataframe(df.describe(include="all").transpose(), use_container_width=True)

        st.markdown("#### ğŸ’¾ ×”×•×¨×“×ª ×”× ×ª×•× ×™× (CSV)")
        st.download_button(
            "×”×•×¨×“ CSV ××¢×•×“×›×Ÿ",
            data=df.to_csv(index=False).encode("utf-8"),
            file_name="data_clean.csv",
            mime="text/csv",
        )
    else:
        st.info("×˜×¨× × ×˜×¢× ×• × ×ª×•× ×™×. ×”×¢×œ×”/×™ ×§×•×‘×¥ ××• ×”×¤×¢×œ/×™ × ×ª×•× ×™ ×“×•×’××”.")

# =======================
# Chart Tab
# =======================
with tab_chart:
    st.markdown("### ğŸ“Š ×’×¨×£ ×¢××•×“×•×ª ×™×¦×™×‘ (×›×•×œ×œ ×ª××™×›×” ×‘×¢×¨×›×™ 0)")
    if "df" not in st.session_state:
        st.info("×¨××©×™×ª, ×˜×¢×Ÿ/×™ × ×ª×•× ×™× ×‘×œ×©×•× ×™×ª '× ×ª×•× ×™×'.")
    else:
        df = st.session_state.df.copy()
        numeric_cols = guess_numeric_columns(df)
        if not numeric_cols:
            st.warning("×œ× × ××¦××• ×¢××•×“×•×ª ×©× ×™×ª×Ÿ ×œ×”××™×¨ ×œ××¡×¤×¨×™×•×ª.")
        else:
            col = st.selectbox("×‘×—×¨/×™ ×¢××•×“×” ××¡×¤×¨×™×ª", options=numeric_cols, index=0)
            user_label = st.text_input("×ª×•×•×™×ª ×¦×™×¨-Y (×©× ×”×¡×“×¨×”)", value=col or "Value")
            safe_label, raw_label = sanitize_field_name(user_label or "Value", default="Value")

            cat_opts = ["(Index)"] + df.columns.tolist()
            cat_col = st.selectbox("×‘×—×¨/×™ ×¢××•×“×ª ×§×˜×’×•×¨×™×” (×œ× ×—×•×‘×”)", options=cat_opts, index=0)

            series = ensure_numeric(df[col])

            if cat_col == "(Index)":
                chart = make_bar_chart(series, label=user_label or "Value")
            else:
                grouped = (
                    pd.DataFrame({"cat": df[cat_col].astype(str), safe_label: series})
                    .groupby("cat", as_index=False)[safe_label].sum()
                )
                chart = (
                    alt.Chart(grouped)
                    .mark_bar()
                    .encode(
                        x=alt.X(field="cat", type="nominal", title=cat_col),
                        y=alt.Y(field=safe_label, type="quantitative", title=raw_label),
                    )
                    .properties(height=340)
                )
            st.altair_chart(chart, use_container_width=True)

# =======================
# Tools Tab
# =======================
with tab_tools:
    st.markdown("### ğŸ› ï¸ ×›×œ×™×")
    if "df" in st.session_state:
        df = st.session_state.df.copy()
        st.markdown("#### ×˜×™×¤×•×¡×™× ×•-Nulls")
        info_df = pd.DataFrame({"dtype": df.dtypes.astype(str), "nulls": df.isna().sum()})
        st.dataframe(info_df, use_container_width=True)

        st.markdown("#### ×”××¨×ª ×¢××•×“×•×ª ×œ××¡×¤×¨×™×™× (coerceâ†’NaNâ†’0)")
        cols_to_convert = st.multiselect(
            "×‘×—×¨/×™ ×¢××•×“×•×ª ×œ×”××¨×”",
            options=df.columns.tolist(),
            default=[c for c in df.columns if c.lower() in ("value", "amount", "price")],
        )
        if st.button("×”××¨/×™ ×œ××¡×¤×¨×™×™×"):
            for c in cols_to_convert:
                df[c] = ensure_numeric(df[c])
            st.session_state.df = df
            st.success("×”×¢××•×“×•×ª ×”×•××¨×•. ×¢×‘×¨/×™ ×œ×œ×©×•× ×™×ª '×’×¨×£' ×›×“×™ ×œ×”××—×™×©.")
            st.dataframe(df.head(30), use_container_width=True)
    else:
        st.info("×¨××©×™×ª, ×˜×¢×Ÿ/×™ × ×ª×•× ×™× ×‘×œ×©×•× ×™×ª '× ×ª×•× ×™×'.")

# =======================
# AI Tab
# =======================
with tab_ai:
    st.markdown("## ğŸ¤– ×›×œ×™× ×—×›××™× (×œ×œ× ××™× ×˜×’×¨×¦×™×” ×—×™×¦×•× ×™×ª)")
    st.caption("×¡×™×›×•× ×˜×§×¡×˜ ×•× ×™×ª×•×— ×¡× ×˜×™×× ×˜. ×× ××•×ª×§×Ÿ transformers â€” ×™×•×¤×¢×œ ××•×“×œ ×¡× ×˜×™×× ×˜ '×××™×ª×™'; ××—×¨×ª, × ×™×ª×•×— ×§×œ×™×œ ××•×‘× ×”.")

    st.markdown("### âœ‚ï¸ ×¡×™×›×•× ×˜×§×¡×˜")
    text_to_sum = st.text_area("×”×“×‘×§/×™ ××• ×›×ª×•×‘/×™ ×˜×§×¡×˜ ×œ×¡×™×›×•×", height=160, placeholder="×”×›× ×¡/×™ ×˜×§×¡×˜ ×‘×¢×‘×¨×™×ª ××• ×‘×× ×’×œ×™×ª...")
    max_sents = st.slider("××¡×¤×¨ ××©×¤×˜×™× ×‘×¡×™×›×•×", min_value=2, max_value=10, value=5, step=1)
    if st.button("×¡×›×/×™"):
        if text_to_sum.strip():
            summary = summarize_text_light(text_to_sum, max_sentences=max_sents)
            st.write("**×¡×™×›×•×:**")
            st.write(summary)
        else:
            st.warning("× × ×œ×”×–×™×Ÿ ×˜×§×¡×˜.")

    st.divider()
    st.markdown("### ğŸ™‚ × ×™×ª×•×— ×¡× ×˜×™×× ×˜")
    sent_text = st.text_area("×˜×§×¡×˜ ×œ× ×™×ª×•×— ×¨×’×©", height=120, placeholder="×›×ª×•×‘/×™ ××©×¤×˜ ×œ×”×¢×¨×›×ª ×—×™×•×‘×™/×©×œ×™×œ×™/× ×™×˜×¨×œ×™")
    use_transformers = st.toggle("×”×©×ª××©/×™ ×‘-transformers ×× ×–××™×Ÿ", value=TRANSFORMERS_AVAILABLE)
    if st.button("× ×ª×—/×™"):
        if not sent_text.strip():
            st.warning("× × ×œ×”×–×™×Ÿ ×˜×§×¡×˜.")
        else:
            if use_transformers and TRANSFORMERS_AVAILABLE:
                nlp = get_sentiment_pipeline()
                if nlp is None:
                    st.info("×œ× × ××¦× ××•×“×œ ×–××™×Ÿ, ××©×ª××©×™× ×‘× ×™×ª×•×— ×”×§×œ×™×œ.")
                    res = sentiment_simple(sent_text)
                    st.write(f"**×ª×•×¦××”:** {res['label']} (×‘×˜×—×•×Ÿ {res['score']:.2f})")
                else:
                    out = nlp(sent_text)[0]
                    label = out.get("label", "")
                    score = out.get("score", 0.0)
                    st.write(f"**×ª×•×¦××” (transformers):** {label} (×‘×˜×—×•×Ÿ {score:.2f})")
            else:
                res = sentiment_simple(sent_text)
                st.write(f"**×ª×•×¦××”:** {res['label']} (×‘×˜×—×•×Ÿ {res['score']:.2f})")
                st.caption("×˜×™×¤: ×œ×”×ª× ×¡×•×ª ×‘××•×“×œ ×××™×ª×™, ×”×•×¡×£/×™ ×œ×—×‘×™×œ×•×ª: transformers, torch (××•×¤×¦×™×•× ×œ×™).")
